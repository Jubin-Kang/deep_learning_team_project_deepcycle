from ultralytics import YOLO
import cv2
import base64
import requests
import time
import socket
import json
import numpy as np

# ===============================
# YOLO ë° ì„œë²„ ê¸°ë³¸ ì„¤ì •
# ===============================
MODEL_PATH = "/home/lim/dev_ws/deepcycle/12_model.pt"
TCP_SERVER_URL = "http://192.168.0.48:5000/upload"
RECYCLE_CENTER_ID = 1

# ===============================
# PyQt í´ë¼ì´ì–¸íŠ¸ í†µì‹  ì„¤ì • (UDP)
# ===============================
PYQT_IP = "192.168.0.100"
PYQT_PORT = 6000
pyqt_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

# ===============================
# ëª¨ë¸ ë¡œë“œ
# ===============================
model = YOLO(MODEL_PATH)

# ===============================
# í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘ (YOLOv8ì€ ìë™ ì¶”ì¶œ ë¶ˆê°€ ì‹œ ìˆ˜ë™ ì…ë ¥ í•„ìš”)
# ===============================
CLASS_NAMES = {
    0: "ì¢…ì´", 1: "ì¢…ì´íŒ©", 2: "ì¢…ì´ì»µ", 3: "ìº”ë¥˜", 4: "ìœ ë¦¬ë³‘",
    5: "í˜íŠ¸", 6: "í”Œë¼ìŠ¤í‹±", 7: "ë¹„ë‹", 8: "ìœ ë¦¬+ë‹¤ì¤‘í¬ì¥ì¬",
    9: "í˜íŠ¸+ë‹¤ì¤‘í¬ì¥ì¬", 10: "ìŠ¤í‹°ë¡œí¼", 11: "ê±´ì „ì§€"
}

# ===============================
# Flask ì„œë²„ë¡œ ì „ì†¡ í•¨ìˆ˜ ì •ì˜
# ===============================
def send_results(image_b64, class_name):
    data = {
        "recycle_center_id": RECYCLE_CENTER_ID,
        "image": image_b64,
        "extension": "jpg",
        "class_name": class_name
    }
    try:
        response = requests.post(TCP_SERVER_URL, json=data)
        print(f"ğŸŸ¢ Flask ì„œë²„ ì‘ë‹µ: {response.json()}")
    except Exception as e:
        print(f"âŒ Flask ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ===============================
# IOU ê³„ì‚° í•¨ìˆ˜ (ê°ì²´ ë™ì¼ì„± íŒë‹¨ìš©)
# ===============================
def iou(box1, box2):
    xi1 = max(box1[0], box2[0])
    yi1 = max(box1[1], box2[1])
    xi2 = min(box1[2], box2[2])
    yi2 = min(box1[3], box2[3])
    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union_area = box1_area + box2_area - inter_area
    return inter_area / union_area if union_area else 0

# ===============================
# PyQtë¡œë¶€í„° ì˜ìƒ ìˆ˜ì‹  (UDP ìŠ¤íŠ¸ë¦¬ë°)
# ===============================
cap = cv2.VideoCapture("udp://0.0.0.0:1234", cv2.CAP_FFMPEG)

# ===============================
# ë©”ì¸ ë£¨í”„ (ê°ì²´ ê°ì§€/ì¶”ì  ë° í†µì‹ )
# ===============================
last_sent_time = 0
tracker = None
tracking = False
tracker_box = None
prev_class_id = None
prev_box = None
tracking_start_time = 0
MAX_TRACK_DURATION = 3

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âŒ í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨")
        continue

    current_time = time.time()
    send_flag = False

    if not tracking or current_time - tracking_start_time > MAX_TRACK_DURATION:
        results = model.predict(frame, imgsz=640, conf=0.25, verbose=False)[0]

        best_class_id = None
        max_conf = 0.0
        best_box = None

        for box in results.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            conf = float(box.conf[0])
            cls = int(box.cls[0])
            if conf > max_conf:
                max_conf = conf
                best_class_id = cls
                best_box = [x1, y1, x2, y2]

        if best_box is not None:
            if prev_box is None or iou(prev_box, best_box) < 0.5 or best_class_id != prev_class_id:
                from opencv_tracker_factory import create_tracker
                tracker = create_tracker("KCF")
                bbox = (best_box[0], best_box[1], best_box[2]-best_box[0], best_box[3]-best_box[1])
                tracker.init(frame, bbox)
                tracking = True
                tracker_box = best_box
                prev_class_id = best_class_id
                prev_box = best_box
                tracking_start_time = current_time
                send_flag = True
            else:
                print("ğŸ” ë™ì¼ ê°ì²´ë¡œ íŒë‹¨ë¨ â†’ ì „ì†¡ ìƒëµ")
                tracking = False
    else:
        success, box = tracker.update(frame)
        if success:
            x, y, w, h = map(int, box)
            tracker_box = [x, y, x + w, y + h]
            if current_time - last_sent_time >= 1:
                send_flag = True
        else:
            print("ğŸ” ì¶”ì  ì‹¤íŒ¨ â†’ ì¬íƒì§€ ì˜ˆì •")
            tracking = False
            continue

    # ===============================
    # PyQt í´ë¼ì´ì–¸íŠ¸ë¡œ ì‹¤ì‹œê°„ ì •ë³´ ì „ì†¡ (í•­ìƒ)
    # ===============================
    if tracker_box is not None:
        result_packet_live = {
            "class_name": CLASS_NAMES.get(prev_class_id, "Unknown"),
            "confidence": float(round(max_conf, 2)),
            "box": list(map(int, tracker_box))
        }
        try:
            pyqt_sock.sendto(json.dumps(result_packet_live).encode(), (PYQT_IP, PYQT_PORT))
        except Exception as e:
            print(f"âš ï¸ PyQt ì‹¤ì‹œê°„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    # ===============================
    # Flask ì„œë²„ë¡œ ì „ì†¡ (ì¡°ê±´ ë§Œì¡± ì‹œ 1íšŒ ë˜ëŠ” ì£¼ê¸° ì „ì†¡)
    # ===============================
    if send_flag and tracker_box is not None:
        best_class_name = CLASS_NAMES.get(prev_class_id, "Unknown")
        ret, buffer = cv2.imencode(".jpg", frame)
        image_b64 = base64.b64encode(buffer).decode('utf-8')
        send_results(image_b64, best_class_name)
        print(f"ğŸ“¡ Flaskë¡œ ê°ì§€ ê²°ê³¼ ì „ì†¡: {best_class_name}")
        last_sent_time = current_time

    # ===============================
    # GUI
    # ===============================
    cv2.imshow("DeepCycle AI - YOLOv8 + Tracker", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

