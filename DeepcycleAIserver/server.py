import socket
import cv2
import numpy as np
import threading
import queue
import time
import json
import requests
from flask import request
from yolo_detector import YoloDetector, CLASS_NAMES
from utils import encode_image_to_base64, iou

# ë””ë²„ê¹…
SEND_TRAINING_DATA = True

# YOLO ëª¨ë¸ ë¡œë“œ
MODEL_PATH = "/home/lim/dev_ws/deepcycle/12_model.pt"
detector = YoloDetector(MODEL_PATH)

# Flask + PyQt ì„¤ì •
TCP_SERVER_URL = "http://192.168.0.48:5000/upload"
RECYCLE_CENTER_ID = 1
PYQT_IP = "192.168.0.100"
PYQT_PORT = 6000
pyqt_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

# Queue ìƒì„±
frame_queue = queue.Queue(maxsize=3)
result_queue = queue.Queue(maxsize=3)

CONF_THRESHOLD = 0.5
DURATION = 5  # seconds for batching detections

YOLO_CLASS_TO_SERVER_ID = {
    "ì¢…ì´": 1, "ì¢…ì´íŒ©": 1, "ì¢…ì´ì»µ": 1,
    "ìº”ë¥˜": 2,
    "ìœ ë¦¬ë³‘": 3,
    "í˜íŠ¸": 4, "í”Œë¼ìŠ¤í‹±": 4,
    "ë¹„ë‹": 5,
    "ìœ ë¦¬+ë‹¤ì¤‘í¬ì¥ì¬": 6,
    "í˜íŠ¸+ë‹¤ì¤‘í¬ì¥ì¬": 6,
    "ìŠ¤í‹°ë¡œí¼": 6,
    "ê±´ì „ì§€": 7
}

# ========== Thread 1: í”„ë ˆì„ ìˆ˜ì‹  ==========
class FrameReceiverThread(threading.Thread):
    def run(self):
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        sock.bind(("0.0.0.0", 1234))
        print("[ğŸ”µ] FrameReceiver ì‹œì‘ë¨")
        while True:
            try:
                data, _ = sock.recvfrom(65536)
                frame = cv2.imdecode(np.frombuffer(data, np.uint8), cv2.IMREAD_COLOR)
                if frame is not None:
                    frame_queue.put(frame)
            except Exception as e:
                print(f"[âŒ] FrameReceiver ì˜¤ë¥˜: {e}")

# ========== Thread 2: YOLO ê°ì§€ + Tracker ==========
class InferenceThread(threading.Thread):
    def __init__(self):
        super().__init__()
        self.buffer = []
        self.start_time = time.time()

    def run(self):
        print("[ğŸŸ¡] InferenceThread ì‹œì‘ë¨")
        while True:
            frame = frame_queue.get()
            boxes, class_ids, confs = detector.detect_all(frame)  # <- detect_all() needs to return multiple detections

            for box, class_id, conf in zip(boxes, class_ids, confs):
                if conf >= CONF_THRESHOLD:
                    self.buffer.append((class_id, conf, box, frame))

            if time.time() - self.start_time >= DURATION:
                self.aggregate_and_send()
                self.buffer.clear()
                self.start_time = time.time()
                
    def aggregate_and_send(self):
        if not self.buffer:
            return
        # Step 1: conf >= 0.5 í•„í„°ë§
        filtered = [(cls_id, conf, box, frame) for cls_id, conf, box, frame in self.buffer if conf >= 0.5]
        if not filtered:
            return  # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ì „ì†¡ ì•ˆ í•¨
        
        # Step 2: í´ë˜ìŠ¤ë³„ë¡œ ê·¸ë£¹í™”
        stat = {}
        for class_id, conf, box, frame in filtered:
            stat.setdefault(class_id, []).append((conf, box, frame))
        
        # Step 3: ê°€ì¥ ë§ì´ ë‚˜ì˜¨ í´ë˜ìŠ¤ ì¤‘ ì„ íƒ
        # # â†’ ë¹ˆë„ìˆ˜ê°€ ê°™ì€ ê²½ìš°, í‰ê·  conf ê¸°ì¤€ìœ¼ë¡œ ì„ íƒ
        best_class_id = max(
            stat.items(),
            key=lambda x: (len(x[1]), np.mean([conf for conf, _, _ in x[1]]))
        )[0]
        
        # Step 4: ê·¸ í´ë˜ìŠ¤ ì¤‘ confê°€ ê°€ì¥ ë†’ì€ í•­ëª© ì„ íƒ
        best_conf, best_box, best_frame = max(stat[best_class_id], key=lambda x: x[0])
        
        # Step 5: ì „ì†¡
        result = {
            "frame": best_frame,
            "class_id": best_class_id,
            "box": best_box,
            "conf": best_conf
        }
        
        result_queue.put(result)

# ========== Thread 3: ê²°ê³¼ ì „ì†¡ (Flask + PyQt) ==========
def draw_box_on_frame(frame, box, label=None):
    img = frame.copy()
    x1, y1, x2, y2 = map(int, box)
    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
    if label:
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
    return img

class ResultSenderThread(threading.Thread):
    def run(self):
        print("[ğŸŸ¢] ResultSenderThread ì‹œì‘ë¨")
        while True:
            result = result_queue.get()
            frame = result["frame"]
            class_id = result["class_id"]
            box = result["box"]
            conf = result["conf"]
            class_name = CLASS_NAMES.get(class_id, "Unknown")

            try:
                packet = {
                    "class_name": class_name,
                    "confidence": float(round(conf, 2)),
                    "box": list(map(int, box)),
                    "timestamp": time.time()
                }
                pyqt_sock.sendto(json.dumps(packet).encode(), (PYQT_IP, PYQT_PORT))
            except:
                print("[âš ï¸] PyQt ì „ì†¡ ì‹¤íŒ¨")

            frame_to_send = draw_box_on_frame(frame, box, f"{class_name} ({conf:.2f})") if SEND_TRAINING_DATA else frame
            image_b64 = encode_image_to_base64(frame_to_send)
            server_class_id = YOLO_CLASS_TO_SERVER_ID.get(class_name, -1)

            if image_b64 and server_class_id != -1:
                data = {
                    "deepcycle_center_id": RECYCLE_CENTER_ID,
                    "image": image_b64,
                    "extension": "jpg",
                    "confidence": conf,
                    "class": server_class_id,
                    "box": list(map(int, box))
                }
                try:
                    response = requests.post(TCP_SERVER_URL, json=data)
                    print(f"[ğŸ“¡] Flask ì „ì†¡ë¨ â†’ {class_name}")
                    if response.status_code == 200:
                        print(f"ğŸŸ¢ Flask ì‘ë‹µ: {response.json()}")
                    else:
                        print(f"âš ï¸ Flask ì‘ë‹µ ì˜¤ë¥˜: {response.status_code} - {response.text}")
                except:
                    print("[âŒ] Flask ì „ì†¡ ì‹¤íŒ¨")

# ========== ìŠ¤ë ˆë“œ ì‹¤í–‰ ==========
FrameReceiverThread().start()
InferenceThread().start()
ResultSenderThread().start()

# ë©”ì¸ ìŠ¤ë ˆë“œ : ëŒ€ê¸° 

while True:
    time.sleep(1)
