import sys
sys.path.append("/home/lim/dev_ws/deepcycle/yolov5")

import cv2
import torch
import base64
import requests
import time
import socket
import json
from models.common import DetectMultiBackend
from utils.general import non_max_suppression
import numpy as np

# ===============================
# YOLO ë° ì„œë²„ ê¸°ë³¸ ì„¤ì •
# ===============================
MODEL_PATH = "/home/lim/dev_ws/deepcycle/12_model.pt"  # í•™ìŠµëœ YOLO ëª¨ë¸ ê²½ë¡œ
TCP_SERVER_URL = "http://192.168.0.48:5000/upload"     # Flask ì„œë²„ URL
RECYCLE_CENTER_ID = 1  # ì¬í™œìš© ì„¼í„° ID ê°’ ì „ì†¡ìš©

# ===============================
# PyQt í´ë¼ì´ì–¸íŠ¸ í†µì‹  ì„¤ì • (UDP)
# ===============================
PYQT_IP = "192.168.0.100"  # PyQt í´ë¼ì´ì–¸íŠ¸ IP
PYQT_PORT = 6000  # PyQtê°€ ìˆ˜ì‹ í•  í¬íŠ¸
pyqt_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # UDP ì†Œì¼“ ìƒì„±

# ===============================
# ëª¨ë¸ ë¡œë“œ ë° ì„¤ì •
# ===============================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = DetectMultiBackend(MODEL_PATH, device=device)
model.eval()

# ===============================
# í´ë˜ìŠ¤ ì´ë¦„ ë§¤í•‘
# ===============================
CLASS_NAMES = {
    0: "ì¢…ì´", 1: "ì¢…ì´íŒ©", 2: "ì¢…ì´ì»µ", 3: "ìº”ë¥˜", 4: "ìœ ë¦¬ë³‘",
    5: "í˜íŠ¸", 6: "í”Œë¼ìŠ¤í‹±", 7: "ë¹„ë‹", 8: "ìœ ë¦¬+ë‹¤ì¤‘í¬ì¥ì¬",
    9: "í˜íŠ¸+ë‹¤ì¤‘í¬ì¥ì¬", 10: "ìŠ¤í‹°ë¡œí¼", 11: "ê±´ì „ì§€"
}

# ===============================
# PyQtë¡œë¶€í„° ì˜ìƒ ìˆ˜ì‹  (UDP ìŠ¤íŠ¸ë¦¬ë°)
# ===============================
cap = cv2.VideoCapture("udp://0.0.0.0:1234", cv2.CAP_FFMPEG)

# ===============================
# Flask ì„œë²„ë¡œ ì „ì†¡ í•¨ìˆ˜ ì •ì˜
# ===============================
def send_results(image_b64, class_name):
    data = {
        "recycle_center_id": RECYCLE_CENTER_ID,
        "image": image_b64,
        "extension": "jpg",
        "class_name": class_name
    }
    try:
        response = requests.post(TCP_SERVER_URL, json=data)
        print(f"ğŸŸ¢ Flask ì„œë²„ ì‘ë‹µ: {response.json()}")
    except Exception as e:
        print(f"âŒ Flask ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ===============================
# IOU ê³„ì‚° í•¨ìˆ˜ (ê°ì²´ ë™ì¼ì„± íŒë‹¨ìš©)
# ===============================
def iou(box1, box2):
    xi1 = max(box1[0], box2[0])
    yi1 = max(box1[1], box2[1])
    xi2 = min(box1[2], box2[2])
    yi2 = min(box1[3], box2[3])
    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)
    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])
    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])
    union_area = box1_area + box2_area - inter_area
    return inter_area / union_area if union_area else 0

# ===============================
# ë©”ì¸ ë£¨í”„ (ê°ì²´ ê°ì§€/ì¶”ì  ë° í†µì‹ )
# ===============================
last_sent_time = 0
tracker = None
tracking = False
tracker_box = None
prev_class_id = None
prev_box = None
tracking_start_time = 0
MAX_TRACK_DURATION = 3  # íŠ¸ë˜ì»¤ ìœ ì§€ ì‹œê°„ (ì´ˆ)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("âŒ í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨")
        continue

    current_time = time.time()
    send_flag = False

    if not tracking or current_time - tracking_start_time > MAX_TRACK_DURATION:
        # ===============================
        # YOLO ê°ì²´ íƒì§€ ìˆ˜í–‰
        # ===============================
        resized = cv2.resize(frame, (640, 640))
        img_tensor = torch.from_numpy(resized).permute(2, 0, 1).float().unsqueeze(0).to(device) / 255.0

        with torch.no_grad():
            pred = model(img_tensor)
            detections = non_max_suppression(pred)

        best_class_id = None
        max_conf = 0.0
        best_box = None

        for det in detections[0]:
            x1, y1, x2, y2, conf, cls = det.cpu().numpy()
            if conf > max_conf:
                max_conf = conf
                best_class_id = int(cls)
                best_box = [int(x1), int(y1), int(x2), int(y2)]

        # ===============================
        # ê°ì²´ ë³€ê²½ ê°ì§€ ë° íŠ¸ë˜í‚¹ ì´ˆê¸°í™” ì¡°ê±´
        # ===============================
        if best_box is not None:
            if prev_box is None or iou(prev_box, best_box) < 0.5 or best_class_id != prev_class_id:
                from opencv_tracker_factory import create_tracker
                tracker = create_tracker("KCF")
                bbox = (best_box[0], best_box[1], best_box[2]-best_box[0], best_box[3]-best_box[1])
                tracker.init(frame, bbox)
                tracking = True
                tracker_box = best_box
                prev_class_id = best_class_id
                prev_box = best_box
                tracking_start_time = current_time
                send_flag = True  # ìƒˆë¡œìš´ ê°ì²´ ê°ì§€ â†’ Flask ì „ì†¡ í—ˆìš©
            else:
                print("ğŸ” ë™ì¼ ê°ì²´ë¡œ íŒë‹¨ë¨ â†’ ì „ì†¡ ìƒëµ")
                tracking = False
    else:
        # ===============================
        # íŠ¸ë˜ì»¤ë¡œ ê°ì²´ ìœ„ì¹˜ ì¶”ì 
        # ===============================
        success, box = tracker.update(frame)
        if success:
            x, y, w, h = map(int, box)
            tracker_box = [x, y, x + w, y + h]
            if current_time - last_sent_time >= 1:
                send_flag = True
        else:
            print("ğŸ” ì¶”ì  ì‹¤íŒ¨ â†’ ì¬íƒì§€ ì˜ˆì •")
            tracking = False
            continue

    # ===============================
    # PyQt í´ë¼ì´ì–¸íŠ¸ë¡œ ì‹¤ì‹œê°„ ì •ë³´ ì „ì†¡ (í•­ìƒ)
    # ===============================
    if tracker_box is not None:
        result_packet_live = {
            "class_name": CLASS_NAMES.get(prev_class_id, "Unknown"),
            "confidence": float(round(max_conf, 2)),
            "box": list(map(int, tracker_box)) 
        }
        try:
            pyqt_sock.sendto(json.dumps(result_packet_live).encode(), (PYQT_IP, PYQT_PORT))
        except Exception as e:
            print(f"âš ï¸ PyQt ì‹¤ì‹œê°„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    # ===============================
    # Flask ì„œë²„ë¡œ ì „ì†¡ (ì¡°ê±´ ë§Œì¡± ì‹œ 1íšŒ ë˜ëŠ” ì£¼ê¸° ì „ì†¡)
    # ===============================
    if send_flag and tracker_box is not None:
        best_class_name = CLASS_NAMES.get(prev_class_id, "Unknown")
        ret, buffer = cv2.imencode(".jpg", frame)
        image_b64 = base64.b64encode(buffer).decode('utf-8')
        send_results(image_b64, best_class_name)
        print(f"ğŸ“¡ Flaskë¡œ ê°ì§€ ê²°ê³¼ ì „ì†¡: {best_class_name}")
        last_sent_time = current_time

    # ===============================
    # GUI
    # ===============================
    cv2.imshow("DeepCycle AI - YOLO + Tracker", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

