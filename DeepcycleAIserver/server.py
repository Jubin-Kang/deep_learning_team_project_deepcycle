import cv2
import base64
import requests
import time
import socket
import json
import numpy as np

from yolo_detector import YoloDetector, CLASS_NAMES
from utils import iou, encode_image_to_base64
from opencv_tracker_factory import create_tracker

# ===============================
# ì¬ë§¤í•‘
# ===============================

YOLO_CLASS_TO_SERVER_ID = {
    "ì¢…ì´": 0, "ì¢…ì´íŒ©": 0, "ì¢…ì´ì»µ": 0,
    "ìº”ë¥˜": 1,
    "ìœ ë¦¬ë³‘": 2,
    "í˜íŠ¸": 3, "í”Œë¼ìŠ¤í‹±": 3,
    "ë¹„ë‹": 4, "ê±´ì „ì§€": 4,
    "ìœ ë¦¬+ë‹¤ì¤‘í¬ì¥ì¬": 5,
    "í˜íŠ¸+ë‹¤ì¤‘í¬ì¥ì¬": 5,
    "ìŠ¤í‹°ë¡œí¼": 5
}

# ===============================
# ê¸°ë³¸ ì„¤ì •
# ===============================
VERBOSE = False # ë””ë²„ê¹… ë©”ì„¸ì§€ ì œì–´ 

MODEL_PATH = "/home/lim/dev_ws/deepcycle/12_model.pt"
TCP_SERVER_URL = "http://192.168.0.48:5000/upload"
RECYCLE_CENTER_ID = 1

PYQT_IP = "192.168.0.100"
PYQT_PORT = 6000
pyqt_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)

# YOLO ê°ì²´ ìƒì„±
detector = YoloDetector(MODEL_PATH)

CONF_THRESHOLD = 0.5  # ìµœì†Œ ì‹ ë¢°ë„ ì„¤ì •

last_class_sent_time = {} # í´ë˜ìŠ¤ë³„ ë§ˆì§€ë§‰ ì „ì†¡ ì‹œê°
skip_count = {} # í´ë˜ìŠ¤ë³„ ê±´ë„ˆë›´ íšŸìˆ˜ ì§€ì •
MIN_SEND_INTERVAL = 2  # ë™ì¼ í´ë˜ìŠ¤ ìµœì†Œ ì „ì†¡ ê°„ê²© (ì´ˆ)

# ===============================
# Flask ì„œë²„ë¡œ ì „ì†¡ í•¨ìˆ˜
# ===============================
def send_results(image_b64, class_name, confidence, box):    
    mapped_id = YOLO_CLASS_TO_SERVER_ID.get(class_name, -1)
    
    if mapped_id == -1:
        print(f"âš ï¸ ì„œë²„ë¡œ ì „ì†¡ ë¶ˆê°€ëŠ¥í•œ í´ë˜ìŠ¤: {class_name}")
        return

    data = {
        "deepcycle_center_id": RECYCLE_CENTER_ID,
        "image": image_b64,
        "extension": "jpg",
        "confidence": confidence,
        "class": mapped_id,
        "box": list(map(int, box))
    }
    try:
        response = requests.post(TCP_SERVER_URL, json=data)
        if response.status_code == 200:
            print(f"ğŸŸ¢ Flask ì‘ë‹µ: {response.json()}")
        else:
            print(f"âš ï¸ Flask ì‘ë‹µ ì˜¤ë¥˜: {response.status_code} - {response.text}")
    except Exception as e:
        print(f"âŒ Flask ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

# ===============================
# ì˜ìƒ ìˆ˜ì‹  (PyQt UDP ìŠ¤íŠ¸ë¦¬ë°)
# ===============================
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
sock.bind(("0.0.0.0", 1234))
print("ğŸ“¡ UDP ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

# ===============================
# ë©”ì¸ ë£¨í”„
# ===============================
tracker = None
tracking = False
tracker_box = None
prev_class_id = None
prev_box = None
tracking_start_time = 0
last_sent_time = 0
MAX_TRACK_DURATION = 3

while True:
    try:
        data, _ = sock.recvfrom(65536)
        np_data = np.frombuffer(data, dtype=np.uint8)
        frame = cv2.imdecode(np_data, cv2.IMREAD_COLOR)
        if frame is None:
            print("âŒ ë””ì½”ë”© ì‹¤íŒ¨")
            continue
    except Exception as e:
        print(f"âŒ ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
        continue

    current_time = time.time()
    send_flag = False

    # === ê°ì²´ ê°ì§€ ===
    if not tracking or current_time - tracking_start_time > MAX_TRACK_DURATION:
        best_box, best_class_id, max_conf = detector.detect(frame)
        class_name = CLASS_NAMES.get(best_class_id, "Unknown")

        if best_box:
            x1, y1, x2, y2 = map(int, best_box)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, f"{class_name} ({max_conf:.2f})", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

        if max_conf < CONF_THRESHOLD:
            if VERBOSE:
                print(f"âš ï¸ ë‚®ì€ conf={max_conf:.2f} â†’ {class_name} ìƒëµ")
            continue

        if best_box is not None:
            if prev_box is None or iou(prev_box, best_box) < 0.5 or best_class_id != prev_class_id:
                bbox = (best_box[0], best_box[1], best_box[2] - best_box[0], best_box[3] - best_box[1])
                tracker = create_tracker("KCF")
                tracker.init(frame, bbox)

                tracker_box = best_box
                prev_class_id = best_class_id
                prev_box = best_box
                tracking_start_time = current_time
                tracking = True
                send_flag = True
            else:
                tracking = False
    else:
        success, box = tracker.update(frame)
        if success:
            x, y, w, h = map(int, box)
            tracker_box = [x, y, x + w, y + h]
            if current_time - last_sent_time >= 1:
                send_flag = True
        else:
            print("ğŸ” ì¶”ì  ì‹¤íŒ¨ â†’ ì¬íƒì§€ ì˜ˆì •")
            tracking = False
            continue

    # === PyQtë¡œ ì‹¤ì‹œê°„ ê²°ê³¼ ì „ì†¡ ===
    if tracker_box is not None:
        result_packet_live = {
            "class_name": CLASS_NAMES.get(prev_class_id, "Unknown"),
            "confidence": float(round(max_conf, 2)),
            "box": list(map(int, tracker_box))
        }
        try:
            pyqt_sock.sendto(json.dumps(result_packet_live).encode(), (PYQT_IP, PYQT_PORT))
        except Exception as e:
            print(f"âš ï¸ PyQt ì „ì†¡ ì‹¤íŒ¨: {e}")

    # === Flaskë¡œ 1íšŒ ì „ì†¡ ===
    if send_flag and tracker_box is not None:
        class_name = CLASS_NAMES.get(prev_class_id, "Unknown")
        now = time.time()
        last_time = last_class_sent_time.get(prev_class_id, 0)
        skip_count[class_name] = skip_count.get(class_name, 0) + 1

        if skip_count[class_name] % 10 == 0:
            print(f"â¸ï¸ {class_name} ìµœê·¼ ì „ì†¡ë¨ â†’ {skip_count[class_name]}íšŒ ëˆ„ì  ìƒëµ")

        image_b64 = encode_image_to_base64(frame)
        if image_b64:
            send_results(image_b64, class_name, max_conf, tracker_box)
            print(f"ğŸ“¡ Flask ì „ì†¡: {class_name}")
            last_sent_time = current_time
            last_class_sent_time[prev_class_id] = now

    # === GUI ë””ë²„ê¹… í™•ì¸ìš© ===
    cv2.imshow("DeepCycle AI - YOLOv8 + Tracker", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

sock.close()
cv2.destroyAllWindows()
